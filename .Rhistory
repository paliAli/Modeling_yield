source("~/.active-rstudio-document", echo=TRUE)
# Finding and repairing errors
prodSum <- function(x,y){
a <- x*y
b <- x+y
return(a,b)}
prodSum(4,5)
# Corrected - can only return one object
prodSum <- function(x, y) {
a <- x * y
b <- x + y
return(list(product = a, sum = b))
}
prodSum(4,5)
input <- "I am a character“
if (typeof(input) = "character"){ print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){ print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character"
if (typeof(input) == "character") {
print("Hooray! This is a character!")
} else {
print("Cant you even type some text???")
}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character"
if (typeof(input) == "character") {
print("Hooray! This is a character!")
} else {
print("Cant you even type some text???")
}
source("~/ETH_courses/Biogeochemical modelling/Bayesian_calibration_exercise.R", echo=TRUE)
# Import libraries ----
library("ggplot2")
library("ggthemes")
library("PerformanceAnalytics")
library("dplyr")
library("deSolve")
# Initial values ----
# Create measurement data frame
measurements <- data.frame(years = c(1, 2, 3, 4), measured = c(55, 28, 16, 7))
measurements$sd <- 5
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Assign the parameter set to the model
# Define the initial state of the system (in this case the intercept)
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x="years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$y, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system (in this case the intercept) for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- euler(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData<-rbind(posteriorData,OneSample)
}
}
View(posteriorAR)
#plot all samples from the posterior
ggplot(measurements, aes(years, y)) +
geom_point() +
theme_classic() +
geom_path(data = final, aes(x = years, y = y))+
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data=posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, y)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
View(measurements)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorData)
View(prior)
View(measurements)
View(Errors)
View(Errors)
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Assign the parameter set to the model
# Define the initial state of the system
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- euler(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
View(measurements)
View(Errors)
View(prior)
View(prior)
prior$Accept
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
View(prior)
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- -k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
View(prior)
View(prior)
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
View(prior)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
View(posteriorAR)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(measurements)
View(posteriorData)
View(measurements)
View(posteriorData)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorAR)
View(prior)
# Initial values ----
# Create measurement data frame
measurements <- data.frame(years = c(1, 2, 3, 4), measured = c(55, 28, 16, 7))
measurements$sd <- 5
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- -k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
posteriorAR$k
View(posteriorData)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(k = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
#coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
theme_classic() +
#coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
geom_point() +
xlab("years")
source("~/GitHub/Modeling_yield/Input_data/weather_data_2223.R", echo=TRUE)
setwd("~/GitHub/Modeling_yield")
#load specific coordinates
source("Input_data/LowerResolution.R")
latitudes <-  Wanted_Points$Latitude
# Import the weather data
weather <- read.csv("Input_data/Europe_weather_data.csv")
weather$Date <- as.Date(weather$Date, format = "%Y-%m-%d")
# Calculate average temperature
weather <- weather %>%
mutate(
Tmean = (Tmax + Tmin) / 2
)
# Define crop TSUM thresholds ----
TSUM_stages <- c(crop$TSUMEM,crop$TSUMEM + crop$TSUM1, crop$TSUMEM + crop$TSUM1 + crop$TSUM2) # Cumulative TSUM values
DVS_stages <- c(0, 1, 2) # Corresponding development stages
# Create a identifier column for the weather
weather$ID <- paste0(weather$LON, "_", weather$LAT)
Unique_ID <- unique(weather$ID)
# Add a growing season identifier based on sowing dates
DVS_weather <- weather %>%
group_by(ID) %>%
arrange(Date) %>%
mutate(
# Assign Season_ID
Season_ID = sapply(Date, function(date) {
# Obtain year from Date
year <- as.numeric(format(date, "%Y"))
# Obtain month from Date
month <- as.numeric(format(date, "%m"))
# Obtain day from Date
day <- as.numeric(format(date, "%d"))
# Check if there are valid sowing date
if (month >= 10) {
return(year)
} else{
return(year - 1)
}})) %>%
ungroup()
unique(DVS_weather$Season_ID) # Check the unique season IDs
# Compute TSUM and DVS for each location per growing season
DVS_weather <- DVS_weather %>%
group_by(ID, Season_ID) %>%
arrange(Date) %>%
mutate(
TSUM = cumsum(Tmean), # Calculate cumulative sum of temperatures
DVS_stage = approx(x = TSUM_stages, y = DVS_stages, xout = TSUM, rule = 2)$y # Interpolate DVS
) %>%
ungroup()
library(readxl)
library(ggplot2)
library(ggthemes)
library(viridis)
#library(maptools)
library(ggpubr)
library(raster)
library(rgdal)
