#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system (in this case the intercept) for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- euler(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData<-rbind(posteriorData,OneSample)
}
}
View(posteriorAR)
#plot all samples from the posterior
ggplot(measurements, aes(years, y)) +
geom_point() +
theme_classic() +
geom_path(data = final, aes(x = years, y = y))+
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data=posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, y)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
View(measurements)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorData)
View(prior)
View(measurements)
View(Errors)
View(Errors)
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Assign the parameter set to the model
# Define the initial state of the system
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- euler(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
View(measurements)
View(Errors)
View(prior)
View(prior)
prior$Accept
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
View(prior)
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- -k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
View(prior)
View(prior)
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
View(prior)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
View(posteriorAR)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(measurements)
View(posteriorData)
View(measurements)
View(posteriorData)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorAR)
View(prior)
# Initial values ----
# Create measurement data frame
measurements <- data.frame(years = c(1, 2, 3, 4), measured = c(55, 28, 16, 7))
measurements$sd <- 5
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- -k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
posteriorAR$k
View(posteriorData)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(k = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
#coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
theme_classic() +
#coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
geom_point() +
xlab("years")
# Select only year 2024 from DVS_weather
DVS_weather <- DVS_weather[DVS_weather$Year == 2024,]
# Load in crop data
source("Input_data/crop_data.R")
# Required libraries ----
library(deSolve)
library(ggplot2)
# Load in crop data
source("Input_data/crop_data.R")
setwd("~/GitHub/Modeling_yield")
# Load in crop data
source("Input_data/crop_data.R")
# Import the weather data ----
source("Scripts/DVS_calculation.R")
# Initial states ----
initial_leaf_weight <- 0.1
initial_stem_weight <- 0.1
initial_root_weight <- 0.1
initial_storage_weight <- 0
initial_LAI <- 0.1
state <- c(WLV = initial_leaf_weight,
WST = initial_stem_weight,
WRT = initial_root_weight,
WSO = initial_storage_weight,
LAI = initial_LAI)
any(is.na(DVS_weather))
which(is.na(DVS_weather))
# Remove NAs from the weather dataset
DVS_weather <- DVS_weather[complete.cases(DVS_weather), ]
# Define the time step
time_step <- 1 # in days
# Define the model ----
crop_growth <- function(t, state, parameters){
with(as.list(c(state, crop)),{
# Get current weather values
day <- floor(t)
Tmean <- weather_subset$Tmean[day]
SR <- weather_subset$Solar[day]
DVS_now <- weather_subset$DVS_stage[day]
LAI_now <- state["LAI"]
if (any(is.na(c(Tmean, SR, DVS_now, LAI_now)))) {
stop("NA values in weather data or state vector")
}
# Calculate required variables
# Convert total radiation to PAR
PAR <- 0.5 * SR  # About 50% of incoming radiation is PAR (Photosynthetically Active Radiation)
# Intercepted PAR using Beerâ€™s Law
fPAR <- 1 - exp(-k * LAI_now)  # k = light extinction coefficient
# Simplified calculation of photosynthesis
Rd <- Ce * PAR * fPAR # gross assimilation in kg/ha/day
# Maintenance respiration
RM_25 <- WLV*RML + WST*RMS + WRT*RMR + WSO*RMO
RM <- RM_25 * Q10^((Tmean - 25)/10) # maintenance respiration in kg/ha/day
# Net biomass assimilation
if (RM > Rd) {
RM <- Rd # The maintenance respiration cannot exceed the gross assimilation
}
RN <- Rd - RM # net assimilation in kg/ha/day
print(paste("Rd:", Rd, "RM:", RM, "RN:", RN))
if (is.na(RN)) {
stop("RN is NA. Check Rd and RM.")
}
# Partitioning (interpolated from tables based on DVS)
FL <- approx(FLTB_df$DVS, FLTB_df$Value, xout = DVS_now, rule = 2)$y
FS <- approx(FSTB_df$DVS, FSTB_df$Value, xout = DVS_now, rule = 2)$y
FR <- approx(FRTB_df$DVS, FRTB_df$Value, xout = DVS_now, rule = 2)$y
FO <- approx(FOTB_df$DVS, FOTB_df$Value, xout = DVS_now, rule = 2)$y
# Biomass growth
dWLV <- RN * FL #* CVL I would use this if I want to calculate carbon content (?)
dWST <- RN * FS #* CVS
dWRT <- RN * FR #* CVR
dWSO <- RN * FO #* CVO
# LAI growth (based on SLA and max relative rate)
dLAI <- min(RGRLAI * LAI_now, SLA * dWLV) # SLA = specific leaf area in ha/kg
# Stop growth when RN is below a threshold and DVS reaches the end stage
if (RN < 0.01 & DVS_now == 3) {
return(NULL) # Stop simulation
}
return(list(
c(dWLV, dWST, dWRT, dWSO, dLAI),
Rd = Rd,
RN = RN,
DVS = DVS_now
))
})
}
# Select only year 2024 from DVS_weather
DVS_weather <- DVS_weather[DVS_weather$Year == 2024,]
# Select only year 2024 from DVS_weather
DVS_weather <- DVS_weather[DVS_weather$YEAR == 2024,]
# Run the model for each location ----
# Loop the ode function through each weather subset
for(i in 1:length(Unique_ID)) {
weather_subset <- DVS_weather[DVS_weather$ID == Unique_ID[i],]
# Define the time step
time_step <- 1 # in days
# Define the number of time steps
num_steps <- nrow(weather_subset) # Number of observed days
times <- seq(1, num_steps, by = time_step) # Time vector
# Run the model
out <- ode(y = state, times = times, func = crop_growth, parms = crop)
# Convert the output to a data frame
out_df <- as.data.frame(out)
# Save the output to a CSV file
write.csv(out_df, paste0("Output/biomass_production_", Unique_ID[i], ".csv"), row.names = FALSE)
}
# Import the csvs as data frames
biomass_files <- list.files(path = "Output", pattern = "biomass_production_", full.names = TRUE)
biomass_data <- lapply(biomass_files, read.csv)
test <- biomass_data[[1]]
View(test)
View(DVS_weather)
# Plot the results ----
ggplot(test, aes(x = time)) +
geom_line(aes(y = WLV, color = "Leaf weight"), linewidth = 1.2) +
geom_line(aes(y = WST, color = "Stem weight"), linewidth = 1.2) +
geom_line(aes(y = WRT, color = "Root weight"), linewidth = 1.2) +
geom_line(aes(y = WSO, color = "Storage weight"), linewidth = 1.2) +
labs(title = "Biomass Production Over Time",
x = "Time",
y = "Weight (kg/ha)") +
scale_color_manual(values = c("Leaf weight" = "green",
"Stem weight" = "brown",
"Root weight" = "blue",
"Storage weight" = "orange")) +
theme(axis.ticks = element_line(linetype = "blank"),
axis.text.x = element_text(size = 0)) +
theme_minimal()
# Only plot LAI
ggplot(test, aes(x = time, y = LAI)) +
geom_line(color = "purple", linewidth = 1.2) +
labs(title = "Leaf Area Index (LAI) Over Time",
x = "Time",
y = "LAI") +
theme(axis.ticks = element_line(linetype = "blank"),
axis.text.x = element_text(size = 0)) +
theme_minimal()
# Plot the results ----
ggplot(test, aes(x = time)) +
geom_line(aes(y = WLV, color = "Leaf weight"), linewidth = 1.2) +
geom_line(aes(y = WST, color = "Stem weight"), linewidth = 1.2) +
geom_line(aes(y = WRT, color = "Root weight"), linewidth = 1.2) +
geom_line(aes(y = WSO, color = "Storage weight"), linewidth = 1.2) +
labs(title = "Biomass Production Over Time",
x = "Time",
y = "Weight (kg/ha)") +
scale_color_manual(values = c("Leaf weight" = "green",
"Stem weight" = "brown",
"Root weight" = "blue",
"Storage weight" = "orange")) +
theme(axis.ticks = element_line(linetype = "blank"),
axis.text.x = element_text(size = 0)) +
theme_minimal()
