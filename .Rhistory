# Create a dataframe
ICBM_values <- data.frame(year = year,
young = Y,
old = O,
total = total_C)
total_C <- Y + O
# Create a dataframe
ICBM_values <- data.frame(year = year,
young = Y,
old = O,
total = total_C)
# Plot the values
ggplot() +
geom_line(data = ICBM_values, aes(x = year, y = young, color = "Young pool"), linewidth = 1.2) +
geom_line(data = ICBM_values, aes(x = year, y = old, color = "Old pool"), linewidth = 1.2) +
geom_line(data = ICBM_values, aes(x = year, y = total, color = "Total carbon"), linewidth = 1.2) +
theme_classic() +
scale_color_manual(values = c("#402827", "#E38E16", "#1B9E8A")) +
labs(title = "Simulated carbon using the ICBM model",
x = "Time (year)",
y = "Carbon (g C/m2)") +
theme(axis.line = element_line(linetype = "solid"),
axis.ticks = element_line(colour = "black"),
axis.title = element_text(size = 12),
plot.title = element_text(size = 14,
hjust = 0.5),
legend.background = element_rect(colour = "black",
linetype = "solid"))
source("~/.active-rstudio-document", echo=TRUE)
# Finding and repairing errors
prodSum <- function(x,y){
a <- x*y
b <- x+y
return(a,b)}
prodSum(4,5)
# Corrected - can only return one object
prodSum <- function(x, y) {
a <- x * y
b <- x + y
return(list(product = a, sum = b))
}
prodSum(4,5)
input <- "I am a character“
if (typeof(input) = "character"){ print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){ print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character"
if (typeof(input) == "character") {
print("Hooray! This is a character!")
} else {
print("Cant you even type some text???")
}
input <- "I am a character“
if (typeof(input) = "character"){print("Hooray! This is a character!")} else { print("Can't you even type some text???")}
input <- "I am a character"
if (typeof(input) == "character") {
print("Hooray! This is a character!")
} else {
print("Cant you even type some text???")
}
source("~/ETH_courses/Biogeochemical modelling/Bayesian_calibration_exercise.R", echo=TRUE)
# Import libraries ----
library("ggplot2")
library("ggthemes")
library("PerformanceAnalytics")
library("dplyr")
library("deSolve")
# Initial values ----
# Create measurement data frame
measurements <- data.frame(years = c(1, 2, 3, 4), measured = c(55, 28, 16, 7))
measurements$sd <- 5
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Assign the parameter set to the model
# Define the initial state of the system (in this case the intercept)
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x="years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$y, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system (in this case the intercept) for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- euler(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData<-rbind(posteriorData,OneSample)
}
}
View(posteriorAR)
#plot all samples from the posterior
ggplot(measurements, aes(years, y)) +
geom_point() +
theme_classic() +
geom_path(data = final, aes(x = years, y = y))+
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data=posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, y)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
View(measurements)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction,group=id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorData)
View(prior)
View(measurements)
View(Errors)
View(Errors)
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Assign the parameter set to the model
# Define the initial state of the system
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- euler(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
Pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
View(measurements)
View(Errors)
View(prior)
View(prior)
prior$Accept
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
View(prior)
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- -k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
Pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
View(prior)
View(prior)
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
View(prior)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
View(posteriorAR)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
View(posteriorAR)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(measurements)
View(posteriorData)
View(measurements)
View(posteriorData)
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
View(posteriorAR)
View(prior)
# Initial values ----
# Create measurement data frame
measurements <- data.frame(years = c(1, 2, 3, 4), measured = c(55, 28, 16, 7))
measurements$sd <- 5
# Define the model
LinearModel <- function(Time, State, Pars){
with(as.list(c(State, Pars)),{
dC <- -k * C
return(list(c(dC)))
})
}
# Define the time step
time <- seq(0, 5, 0.2)
# Define the initial value
Cini <- 100
State <- c(C = Cini)
# Define the parameres
k <- -.5
pars <- k
# Run the model
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Sampling step ----
SizeOfPrior <- 10000
# Create 10000 random values of k
prior <- data.frame(k = rnorm(n = SizeOfPrior, mean = 1, sd = .5))
# Creating empty columns for to store the probabilities, likelihoods and the predictions
prior$likelihood <- NA
measurements$probability <- NA
# Run the model 10000 times for each k
for(i in 1:nrow(prior)){
# Define the parameters of the model
pars <- c(k = prior$k[i])
# Run the model for the parameter set and make a data frame of the output
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
out <- as.data.frame(out)
# adjusting the name of out to match the data
colnames(out) <- c("years","prediction")
# Step 3.3: Join the prediction of the model for each data point
Errors <- merge(measurements, out, by.x = "years")
# Step 3.4: Compute the probability of observing each data point, given the model and the measurement uncertainty, assuming a normal (gaussian) distribution of errors
Errors$probability <- dnorm(Errors$measured, mean = Errors$prediction, sd = Errors$sd)
# Step 3.5: Compute the likelihood for each parameter set (the product of all individual probabilities)
prior$likelihood[i] <- prod(Errors$probability)
}
#Lmax<-prod(dnorm(x=measurements$y,mean=measurements$y,sd=measurements$sd)) #computing the maximum possible likelihood with the current sample
Lmax <- max(prior$likelihood)
prior$likelihoodRel <- prior$likelihood/Lmax # compute the relative likelihood for each parameters set
prior$Accept <- FALSE
prior$Accept[ ( runif(nrow(prior)) < prior$likelihoodRel )]<-TRUE # create a random number between 1 and 0 for each parameter set, and accept it if the random number is smaller than the relative likelihood
posteriorAR <- prior[prior$Accept,]
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(slope = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
posteriorAR$k
View(posteriorData)
for(i in 1: nrow(posteriorAR)){
# Define the initial state of the system for one sample
State <- c(C = Cini)
# Define the parameters of the model
pars <- c(k = posteriorAR$k[i])
# Run the model for the parameter set and make a data frame of the output for one sample
out <- rk4(y = State, times = time, func = LinearModel, parms = pars)
# Assign the ID of the sample to the output and join the output to the posterior data frame
OneSample <- as.data.frame(out)
colnames(OneSample) <- c("years","prediction")
OneSample$id <- i
if(i == 1){posteriorData <- OneSample}else{
posteriorData <- rbind(posteriorData,OneSample)
}
}
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
# coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
geom_point() +
theme_classic() +
#coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
xlab("years")
#plot all samples from the posterior
ggplot(measurements, aes(years, measured)) +
theme_classic() +
#coord_cartesian(xlim = c(0, 4), ylim = c(0, 4))+
geom_line(data = posteriorData, aes(x = years, y = prediction, group = id),alpha=0.1, color ="blue")+
geom_point() +
xlab("years")
install.packages("Rwofost")
setwd("~/GitHub/Modeling_yield")
?approx
# Load in crop data
crop <- source("~Github/Modelling_yield/Input_data/crop_data.R")
# Load in crop data
crop <- source("~GitHub/Modelling_yield/Input_data/crop_data.R")
# Load in crop data
crop <- source("~/GitHub/Modelling_yield/Input_data/crop_data.R")
# Load in crop data
crop <- source("~/GitHub/Modeling_yield/Input_data/crop_data.R")
View(crop)
View(crop)
crop$value["TSUMEM"]
# Define crop TSUM thresholds ----
TSUM_stages <- c(0, crop$value["TSUM1"], crop$value["TSUM1"] + crop$value["TSUM2"])
crop$value["TSUM1"] + crop$value["TSUM2"]
crop$value["TSUM1"]
crop$value["TSUM2"]
# Define crop TSUM thresholds ----
TSUM_stages <- c(0, crop$value["TSUM1"], sum(crop$value["TSUM1"],crop$value["TSUM2"]))
class(crop$value["TSUM1"])
crop$value[["TSUM1"]]
class(crop$value[["TSUM1"]])
# Define crop TSUM thresholds ----
TSUM_stages <- c(0, crop$value[["TSUM1"]], crop$value[["TSUM1"]] + crop$value[["TSUM2"]])
# Define crop TSUM thresholds ----
TSUM_stages <- c(crop$value[["TSUMEM"]],crop$value[["TSUMEM"]] + crop$value[["TSUM1"]], crop$value[["TSUMEM"]] + crop$value[["TSUM1"]] + crop$value[["TSUM2"]]) # Cumulative TSUM values
DSV_stages <- c(0, 1, 2) # Corresponding development stages
